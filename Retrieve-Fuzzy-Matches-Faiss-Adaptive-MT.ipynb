{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ymoslem/Adaptive-MT-LLM-Fine-tuning/blob/main/Retrieve-Fuzzy-Matches-Faiss-Adaptive-MT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSXaUw_uHCLl"
      },
      "source": [
        "# Create a bilingual dataset with fuzzy matches\n",
        "\n",
        "This notebook is part of the repository [Adaptive-MT-LLM-Fine-tuning](https://github.com/ymoslem/Adaptive-MT-LLM-Fine-tuning)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdxcPWTQG8lf"
      },
      "source": [
        "# Load files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJmg6efdG2a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b8d513c8-a3e1-4e2c-c1b0-3aca5ee96226"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/data/spanish'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/data/\"\n",
        "directory = os.path.join(data_path, \"spanish\")\n",
        "\n",
        "os.chdir(directory)\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l all*"
      ],
      "metadata": {
        "id": "FixTkbV1RBu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test files (FUZZY)\n",
        "source_file_name = \"all-filtered.es.fuzzy.test\"\n",
        "target_file_name = \"all-filtered.en.fuzzy.test\"\n",
        "\n",
        "# Apply the same for training datasets"
      ],
      "metadata": {
        "id": "PCh2Gt5F87xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(source_file_name) as source, open(target_file_name) as target:\n",
        "  source_sentences = [sent.strip() for sent in source.readlines()]\n",
        "  target_sentences = [sent.strip() for sent in target.readlines()]\n",
        "\n",
        "print(source_sentences[0])\n",
        "print(target_sentences[0])"
      ],
      "metadata": {
        "id": "NPNQMxiFRWPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD2nD9y4eSsI"
      },
      "source": [
        "# Indexing the dataset with Faiss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUvIXMUyeWpr"
      },
      "outputs": [],
      "source": [
        "!pip3 install faiss-cpu sentence_transformers &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model to create embeddings\n",
        "# Make sure the model works for the required language\n",
        "\n",
        "model_name = \"microsoft/Multilingual-MiniLM-L12-H384\"\n",
        "\n",
        "# Other model options\n",
        "# model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"  # multilingual\n",
        "# model_name = \"all-MiniLM-L6-v2\"  # English"
      ],
      "metadata": {
        "id": "7JiGZ1OPTJol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "shared_drive = userdata.get(\"shared_drive\")\n",
        "\n",
        "model_directory = os.path.join(shared_drive, \"models\")\n",
        "\n",
        "os.chdir(directory)\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "kXIvLbT7STgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWghpe94nJVL"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "embedder = SentenceTransformer(model_name,\n",
        "                               cache_folder=model_directory,\n",
        "                               device=\"cuda\")\n",
        "\n",
        "# change the max length to 512\n",
        "embedder.max_seq_length = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "617e146523d140f7be0877cd046ecb35",
            "61854bb73c8244d0ac6aeacda4d406c2",
            "ec0fb78405d0438e8529709fb3b80c0e",
            "bcd9aa4a54c341f0b6a6e6440d593d70",
            "85dcca76a29a4b60b585d1b78e743cdb",
            "643f42056e09482cb71d90e117d614c1",
            "411613105044459dbc1b005d0f34c8d9",
            "f739a12ac76740b49251535ed6fb1d76",
            "7231243abc904d18a9c8fb515a4688d1",
            "24353159a6734d5b8810894050f95a7e",
            "2c2528a56b05491c9f2a499faa551b3d"
          ]
        },
        "id": "_2E4DYcNvavr",
        "outputId": "6d528c25-12df-48f0-aeb4-78534e55f2ef"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1563 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "617e146523d140f7be0877cd046ecb35"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# encode the texts into embedding\n",
        "\n",
        "corpus_embeddings = embedder.encode(source_sentences,\n",
        "                                    convert_to_numpy=True,\n",
        "                                    show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving / Loading embeddings"
      ],
      "metadata": {
        "id": "V9oCfykkSpXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the embeddings for the TEST set\n",
        "pkl_file_name = \"medical-testset-embeddings-MS-Multilingual-MiniLM-L12-H384-spanish.pkl\""
      ],
      "metadata": {
        "id": "LTzKJXlNStX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e285b2f"
      },
      "outputs": [],
      "source": [
        "# Save corpus_embeddings to a file to be able to load later\n",
        "import pickle\n",
        "\n",
        "with open(pkl_file_name, \"wb\") as embeddings_pkl:\n",
        "  pickle.dump({\"corpus\": source_sentences,\n",
        "               \"target\": target_sentences,\n",
        "               \"embeddings\": corpus_embeddings,\n",
        "               },\n",
        "              embeddings_pkl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46b69fdb"
      },
      "outputs": [],
      "source": [
        "# To load the embeddings later from the file instead of creating from scratch\n",
        "import pickle\n",
        "\n",
        "with open(pkl_file_name, \"rb\") as embeddings_pkl:\n",
        "  data = pickle.load(embeddings_pkl)\n",
        "  source_sentences = data[\"corpus\"]\n",
        "  target_sentences = data[\"target\"]\n",
        "  corpus_embeddings = data[\"embeddings\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f039fd50",
        "outputId": "dd10cc67-f0d9-4c0c-ec11-a75b576b6a1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 384)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "corpus_embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CcB3cca27P3"
      },
      "source": [
        "## Train a Faiss index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPIlWn8DfybC",
        "outputId": "13c3a042-9558-483c-96c5-868e4e64b221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start creating FAISS index\n",
            "Number of embeddings indexed: 50000\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "\n",
        "# embedding size, same as the model\n",
        "embedding_size = 384\n",
        "\n",
        "# Number of clusters used for faiss\n",
        "# 4*sqrt(N) to 16*sqrt(N) where N is the size of the dataset\n",
        "n_clusters = 4096\n",
        "\n",
        "quantizer = faiss.IndexFlatL2(embedding_size)\n",
        "index = faiss.IndexIVFFlat(quantizer, embedding_size, n_clusters)\n",
        "\n",
        "# Number of clusters to explore at search time.\n",
        "# We will search for nearest neighbors in 32 clusters\n",
        "index.nprobe = 32\n",
        "\n",
        "### Create the FAISS index\n",
        "print(\"Start creating FAISS index\")\n",
        "\n",
        "# Train the index to find a suitable clustering\n",
        "index.train(corpus_embeddings)\n",
        "\n",
        "# Add all embeddings to the index\n",
        "index.add(corpus_embeddings)\n",
        "\n",
        "print(\"Number of embeddings indexed:\", index.ntotal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LATs0DX_7EeB"
      },
      "outputs": [],
      "source": [
        "# Saving the index for the TEST set\n",
        "index_file_name = \"medical-testset-embeddings-IndexIVFFlat-4096-MS-Multilingual-MiniLM-L12-H384-spanish.index\"\n",
        "\n",
        "faiss.write_index(index, index_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLRPxwRi7D85"
      },
      "source": [
        "## Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do6e6Z3w7m6f"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "top_k_hits = 10\n",
        "\n",
        "\n",
        "queries = [\"Niños y adolescentes No se recomienda el uso de Telmisartán Teva en niños y adolescentes hasta 18 años.\"]\n",
        "\n",
        "\n",
        "# Use the same model you used for embedding the dataset\n",
        "model_name = \"microsoft/Multilingual-MiniLM-L12-H384\"\n",
        "\n",
        "# model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"  # multilingual\n",
        "# model_name = \"all-MiniLM-L6-v2\"  # English\n",
        "\n",
        "model = SentenceTransformer(model_name,\n",
        "                            cache_folder=\"/content/drive/MyDrive/models\",\n",
        "                            device=\"cuda\")\n",
        "\n",
        "query_embeddings = model.encode(queries)\n",
        "\n",
        "# Search in FAISS. It returns a matrix with distances and corpus ids.\n",
        "distances, corpus_ids = index.search(query_embeddings,\n",
        "                                     k=top_k_hits)\n",
        "\n",
        "print(corpus_ids, \"\\n\")\n",
        "\n",
        "results = sorted([result for result in zip(distances.flatten(), corpus_ids.flatten())])\n",
        "print(results, \"\\n\")\n",
        "\n",
        "print(queries[0], \"\\n\")\n",
        "\n",
        "for distance, idx in results:\n",
        "  print(source_sentences[idx], sep=\"\\n\")\n",
        "  print(f\"Distance: {round(distance.item(), 2)}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use saved index"
      ],
      "metadata": {
        "id": "PGNqBdnNnrvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install faiss-cpu sentence_transformers &> /dev/null"
      ],
      "metadata": {
        "id": "doRRobgznw48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/data/\"\n",
        "directory = os.path.join(data_path, \"spanish\")\n",
        "\n",
        "os.chdir(directory)\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "tAe1jHK1n7oT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e72557a0-68c2-4d98-96ed-b49699432854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/data/spanish'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the index\n",
        "import faiss\n",
        "\n",
        "# Load the saved index for the test set\n",
        "saved_index = \"medical-testset-embeddings-IndexIVFFlat-4096-MS-Multilingual-MiniLM-L12-H384-spanish.index\"\n",
        "\n",
        "index = faiss.read_index(saved_index)"
      ],
      "metadata": {
        "id": "WYsIPO-roKdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data (and embeddings - not required for search)\n",
        "import pickle\n",
        "\n",
        "# Load the embeddings for the test set\n",
        "pkl_file_name = \"medical-testset-embeddings-MS-Multilingual-MiniLM-L12-H384-spanish.pkl\"\n",
        "\n",
        "with open(pkl_file_name, \"rb\") as embeddings_pkl:\n",
        "  data = pickle.load(embeddings_pkl)\n",
        "  source_sentences = data[\"corpus\"]\n",
        "  target_sentences = data[\"target\"]\n",
        "  corpus_embeddings = data[\"embeddings\"]"
      ],
      "metadata": {
        "id": "U6rtewF1penR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test files (REAL)\n",
        "source_file_name = \"all-filtered.es.real.test\"\n",
        "target_file_name = \"all-filtered.en.real.test\""
      ],
      "metadata": {
        "id": "jpQMVwHDtpBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(source_file_name) as source, open(target_file_name) as target:\n",
        "  online_source_sentences = [sent.strip() for sent in source.readlines()]\n",
        "  online_target_sentences = [sent.strip() for sent in target.readlines()]\n",
        "\n",
        "print(online_source_sentences[0])\n",
        "print(online_target_sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrEvsJj7Q4GJ",
        "outputId": "860e4d70-42f0-4d27-f394-1097b7bee714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El consumo nocivo de alcohol es responsable por cerca de 3% de todas las muertes que ocurren en el planeta, incluyendo desde cirrosis y cáncer hepático hasta accidentes, caídas, intoxicaciones y homicidios.\n",
            "The harmful use of alcohol is responsible for about 3% of all deaths that occur on the planet, ranging from liver cancer and cirrhosis to accidents, falls, poisoning and murder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"microsoft/Multilingual-MiniLM-L12-H384\""
      ],
      "metadata": {
        "id": "sxH89JdG2ouK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST - Find fuzzies\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "top_k_hits = 3  # it can more or less, and 'rerank' the results later\n",
        "\n",
        "index.nprobe = 32\n",
        "\n",
        "queries = online_source_sentences[:5]\n",
        "queries_len = len(queries)\n",
        "\n",
        "model = SentenceTransformer(model_name,\n",
        "                            cache_folder=\"/content/drive/Shareddrives/adapt-yasmin/models/\",\n",
        "                            device=\"cuda\")\n",
        "\n",
        "query_embeddings = model.encode(queries)\n",
        "\n",
        "# Search in FAISS for each query\n",
        "distances, corpus_ids = index.search(query_embeddings,\n",
        "                                     k=top_k_hits)\n",
        "\n",
        "# Process results for each query\n",
        "for query_idx, (dist, ids) in tqdm(enumerate(zip(distances, corpus_ids)), total=queries_len):\n",
        "  print(f\"\\nQuery {query_idx + 1}: {queries[query_idx]}\")\n",
        "  results = sorted([result for result in zip(dist.flatten(), ids.flatten())])\n",
        "\n",
        "  # Store the results of the current query\n",
        "  result_rows = []\n",
        "  for distance, idx in results:\n",
        "    result_rows.append((distance,\n",
        "                        source_sentences[idx],\n",
        "                        target_sentences[idx]\n",
        "                        ))\n",
        "\n",
        "  print(*result_rows, sep=\"\\n\")"
      ],
      "metadata": {
        "id": "cvkyKbxy2JWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_file_name = \"all-filtered.esen.ms-multi-12.online.test\""
      ],
      "metadata": {
        "id": "muv0F80v3ESu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find fuzzies and save to file\n",
        "# We will use top_k_hits 1 to get only one result\n",
        "# If more top_k_hits retrieved, reranking can be used to get the best result\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "top_k_hits = 1\n",
        "\n",
        "index.nprobe = 32\n",
        "\n",
        "queries = online_source_sentences\n",
        "queries_len = len(queries)\n",
        "\n",
        "model = SentenceTransformer(model_name,\n",
        "                            cache_folder=\"/content/drive/Shareddrives/adapt-yasmin/models/\",\n",
        "                            device=\"cuda\")\n",
        "\n",
        "query_embeddings = model.encode(queries)\n",
        "\n",
        "# Search in FAISS for each query\n",
        "distances, corpus_ids = index.search(query_embeddings,\n",
        "                                     k=top_k_hits)\n",
        "\n",
        "# Process results for each query and save to file\n",
        "with open(output_file_name, \"w+\") as output_file:\n",
        "  for query_idx, (dist, ids) in enumerate(zip(distances, corpus_ids)):\n",
        "    results = sorted([result for result in zip(dist.flatten(), ids.flatten())])\n",
        "\n",
        "    # Store the results of the current query\n",
        "    result_rows = []\n",
        "    for distance, idx in results:\n",
        "      result_rows.append((distance,\n",
        "                          source_sentences[idx],\n",
        "                          target_sentences[idx],\n",
        "                          ))\n",
        "\n",
        "    # Save the output to file\n",
        "\n",
        "    score = result_rows[0][0]\n",
        "    new_src_sent = queries[query_idx]\n",
        "    fuzzy_src_sent = result_rows[0][1]\n",
        "    fuzzy_tgt_sent = result_rows[0][2]\n",
        "\n",
        "    output = f\"{score} ||| {fuzzy_src_sent} ||| {new_src_sent} ||| {fuzzy_tgt_sent}\"\n",
        "    output_file.write(output + \"\\n\")\n",
        "\n",
        "    # Check the output for the first few segments\n",
        "    if query_idx >= 0 and query_idx < 3:\n",
        "      print(f\"\\nQuery {query_idx}: {queries[query_idx]}\")\n",
        "      print(output)"
      ],
      "metadata": {
        "id": "Uf22e_cKo1gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 5 $output_file_name"
      ],
      "metadata": {
        "id": "slA5VKQp0y4Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1THf9J_VS-IFIttsN7JpMj4JoZojhhur6",
      "authorship_tag": "ABX9TyMdSDBJvKQ34plz/+Cb3Uda",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "617e146523d140f7be0877cd046ecb35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61854bb73c8244d0ac6aeacda4d406c2",
              "IPY_MODEL_ec0fb78405d0438e8529709fb3b80c0e",
              "IPY_MODEL_bcd9aa4a54c341f0b6a6e6440d593d70"
            ],
            "layout": "IPY_MODEL_85dcca76a29a4b60b585d1b78e743cdb"
          }
        },
        "61854bb73c8244d0ac6aeacda4d406c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_643f42056e09482cb71d90e117d614c1",
            "placeholder": "​",
            "style": "IPY_MODEL_411613105044459dbc1b005d0f34c8d9",
            "value": "Batches: 100%"
          }
        },
        "ec0fb78405d0438e8529709fb3b80c0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f739a12ac76740b49251535ed6fb1d76",
            "max": 1563,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7231243abc904d18a9c8fb515a4688d1",
            "value": 1563
          }
        },
        "bcd9aa4a54c341f0b6a6e6440d593d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24353159a6734d5b8810894050f95a7e",
            "placeholder": "​",
            "style": "IPY_MODEL_2c2528a56b05491c9f2a499faa551b3d",
            "value": " 1563/1563 [00:44&lt;00:00, 71.73it/s]"
          }
        },
        "85dcca76a29a4b60b585d1b78e743cdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "643f42056e09482cb71d90e117d614c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "411613105044459dbc1b005d0f34c8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f739a12ac76740b49251535ed6fb1d76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7231243abc904d18a9c8fb515a4688d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24353159a6734d5b8810894050f95a7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c2528a56b05491c9f2a499faa551b3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}